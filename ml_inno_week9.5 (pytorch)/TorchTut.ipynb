{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UccsLrIDSuJF"
   },
   "source": [
    "## PyTorch Tutorial\n",
    "```\n",
    "- Machine Learning, Innopolis University \n",
    "- Professor: Adil Khan \n",
    "- Teaching Assistant: Gcinizwe Dlamini\n",
    "```\n",
    "<hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4He13qC7StI6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "np.random.seed(73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3dO6a6ce0E3"
   },
   "source": [
    "## <center> Linear Regression with Numpy<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cB1XeGRfWzwL"
   },
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OVKWjKdxTnx-"
   },
   "outputs": [],
   "source": [
    "# Data Generation\n",
    "def generate_data(size = 100):\n",
    "    x = np.random.rand(size, 1)\n",
    "    y = 3 + 2.5 * x + .1 * np.random.randn(size, 1)\n",
    "\n",
    "    # Shuffles the indices\n",
    "    idx = np.arange(size)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    # split to train and validation 80:20\n",
    "    split = int(size * 0.8)\n",
    "    train_idx = idx[:split]\n",
    "    val_idx = idx[split:]\n",
    "\n",
    "    # Generate train and validation sets\n",
    "    x_train, y_train = x[train_idx], y[train_idx]\n",
    "    x_val, y_val = x[val_idx], y[val_idx]\n",
    "\n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "FN5dKNZGW6BA",
    "outputId": "799651c1-83e8-4a3b-f7f6-ff5f1e8bc4a9"
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val = generate_data()\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Title\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTVz4pV6XjXm"
   },
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Gradient descent consist of 3 basic steps : \n",
    "\n",
    "1. **Compute the Loss**\n",
    "\n",
    "$$ \\hat{y} = a + bx + \\epsilon $$\n",
    "\n",
    "$$ \\text{MSE} = \\frac{1}{N} \\sum_{i} (y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "$$ \\text{MSE} = \\frac{1}{N} \\sum_{i} (y_i - a - bx_i)^2 $$\n",
    "\n",
    "2. **Compute the Gradients** : A gradient is a partial derivative. Using the chain rule the final expression came to be : \n",
    "\n",
    "$$\\frac{\\partial \\text{MSE}}{\\partial a} = \\frac{\\partial \\text{MSE}}{\\partial \\hat{y}} * \\frac{\\partial \\hat{y}}{\\partial a} = -2 * \\frac{1}{N} \\sum_{i} (y_i - \\hat{y}_i)$$\n",
    "\n",
    "$$\\frac{\\partial \\text{MSE}}{\\partial b} = \\frac{\\partial \\text{MSE}}{\\partial \\hat{y}} * \\frac{\\partial \\hat{y}}{\\partial b} = -2 * \\frac{1}{N} \\sum_{i} x_i(y_i - \\hat{y}_i)$$\n",
    "\n",
    "3. **Update the Parameters**\n",
    "\n",
    "$$a = a - \\alpha \\frac{\\partial \\text{MSE}}{\\partial a}$$\n",
    "\n",
    "$$b = b - \\alpha \\frac{\\partial \\text{MSE}}{\\partial b}$$\n",
    "\n",
    "4. Repeat step 1 to 3 till convergence is reached\n",
    "\n",
    "\n",
    "### TASK : Implement Step 1 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2EX120SXSid",
    "outputId": "2c0c7f59-2358-41b2-bfb3-8a5548e53b8a"
   },
   "outputs": [],
   "source": [
    "# Initializes parameters \"a\" and \"b\" randomly\n",
    "\n",
    "a = np.random.randn(1)\n",
    "b = np.random.randn(1)\n",
    "\n",
    "print(f\"Initial values of [a, b] : [{a[0]}, {b[0]}]\")\n",
    "\n",
    "learning_rate = 1e-1 #learning rate\n",
    "n_epochs = 1000\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  \n",
    "    # TODO: Step 1: Computes y hat\n",
    "    yhat = None\n",
    "\n",
    "    # TODO: Compute error and Loss using MSE \n",
    "    error = None\n",
    "    loss = None\n",
    "\n",
    "    # TODO : Step 2: Compute gradients for both \"a\" and \"b\" parameters (partial derivatives)\n",
    "    a_grad = None\n",
    "    b_grad = None\n",
    "\n",
    "    # TODO : Step 3: Update parameters using gradients and the learning rate\n",
    "    a = a - learning_rate * a_grad\n",
    "    b = b - learning_rate * b_grad\n",
    "    \n",
    "print(f\"Final values of [a, b] : [{a[0]}, {b[0]}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hE4yi8zQZNXx"
   },
   "source": [
    "## PyTorch implementation\n",
    "\n",
    "1. Simple model using nn.Sequential(..)\n",
    "1. Read input data from file \n",
    "1. Add Tensorboard\n",
    "1. Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ulrawONrZUHp"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import torch.optim as optim # for optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pwi1O6ORQRN"
   },
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dYXofjA5du1h"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch. utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpjxeNVriTOt"
   },
   "source": [
    "### Read Data from local Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wN5rI2KibiWt",
    "outputId": "979f134c-7835-43ae-ddbe-5533b1c10479"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/YoongiKim/CIFAR-10-images.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0stBvUz5Bv-"
   },
   "source": [
    "## Create a CNN Model, Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEO18g00j37t"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    tot_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        tot_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return tot_loss/len(train_loader)\n",
    "            \n",
    "def test( model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format( test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return test_loss, correct/len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8C99RveBmV0K"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model_cnn = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "It92gozt9HSX"
   },
   "source": [
    "## Add TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WKQfL1hk9Gux"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBIrsrBe5XzN"
   },
   "source": [
    "## Use pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mz5ftjMt5XdP"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18(pretrained=True,progress=True)\n",
    "alexnet = models.alexnet(pretrained=True,progress=True)\n",
    "squeezenet = models.squeezenet1_0(pretrained=True,progress=True)\n",
    "vgg16 = models.vgg16(pretrained=True,progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7N9_N4HAJGJQ"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Resize((256,256)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvEAx_-j5wDI"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = models.resnet18(pretrained=True,progress=True)\n",
    "        self.net.trainable = False\n",
    "        self.net.fc = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmQcACIPeueG"
   },
   "source": [
    "## <center> PyTorch Basics<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIBkMQyGB7O6"
   },
   "source": [
    "### Tensors \n",
    "\n",
    "* How to create a Tensor\n",
    "* Operations on tensors\n",
    "* Data types for Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9BiWttzCLJs"
   },
   "source": [
    "### Create a Tensor \n",
    "\n",
    "1. Create tensors from Numpy then see what operations can be applied.\n",
    "**Note:** By default a tensor resides in cpu but can be sent to the GPU for fatser computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vKdsfJNGc86F",
    "outputId": "7f754f1b-75aa-4de8-ba87-237ea3edcb13"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
    "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
    "\n",
    "# Here we can see the difference - notice that .type() is more useful\n",
    "# since it tells WHERE the tensor device\n",
    "\n",
    "print(type(x_train), type(x_train_tensor), x_train_tensor.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxhYLd2dMd15"
   },
   "source": [
    "### Dynamic Computation Graph\n",
    "\n",
    "* Easily visualize a graph using `PyTorchViz` package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUGg1luKNTGk"
   },
   "outputs": [],
   "source": [
    "!pip install torchviz \n",
    "from torchviz import make_dot\n",
    "\n",
    "a = torch.randn(1,requires_grad=True,device=device)\n",
    "b = torch.randn(1,requires_grad=True,device=device)\n",
    "c = torch.randn(1,requires_grad=True,device=device)\n",
    "d = torch.randn(1,requires_grad=True,device=device)\n",
    "\n",
    "f = a**b + b*0.5 + c**3 - d*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "_ch9YEtgNt0T",
    "outputId": "e5df252f-6e79-43dd-e1be-26fb326f7a3c"
   },
   "outputs": [],
   "source": [
    "make_dot(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGcFMG-NRbZ8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TorchTut.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
